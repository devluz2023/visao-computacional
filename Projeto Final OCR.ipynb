{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projeto Final OCR.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devluz2023/visao-computacional/blob/main/Projeto%20Final%20OCR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Projeto Final:\n",
        "Nesse projeto nosso objetivo é:\n",
        "\n",
        "- Buscar termos específicos\n",
        "- Salvar resultados em um arquivo txt\n",
        "- Mostrar os resultados sobre as imagens dos termos específicos\n"
      ],
      "metadata": {
        "id": "Ygwv_z2UFBv2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Preparando o ambiente"
      ],
      "metadata": {
        "id": "TBsY17HOmgGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bibliotecas e dados"
      ],
      "metadata": {
        "id": "BI8HZlV8135n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bLrmRI4nZYlI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "185ac852-2a57-4acb-d23a-443b4609dc6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement opencv-python==4.6.0 (from versions: 3.4.0.14, 3.4.10.37, 3.4.11.39, 3.4.11.41, 3.4.11.43, 3.4.11.45, 3.4.13.47, 3.4.15.55, 3.4.16.57, 3.4.16.59, 3.4.17.61, 3.4.17.63, 3.4.18.65, 4.3.0.38, 4.4.0.40, 4.4.0.42, 4.4.0.44, 4.4.0.46, 4.5.1.48, 4.5.3.56, 4.5.4.58, 4.5.4.60, 4.5.5.62, 4.5.5.64, 4.6.0.66, 4.7.0.68, 4.7.0.72, 4.8.0.74, 4.8.0.76, 4.8.1.78, 4.9.0.80)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for opencv-python==4.6.0\u001b[0m\u001b[31m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 1s (8,493 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n",
            "Collecting reportlab\n",
            "  Downloading reportlab-4.1.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from reportlab) (9.4.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from reportlab) (5.2.0)\n",
            "Installing collected packages: reportlab\n",
            "Successfully installed reportlab-4.1.0\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.23.26-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.23.22 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.23.26 PyMuPDFb-1.23.22\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python==4.6.0\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install reportlab\n",
        "!pip install PyMuPDF\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/sthemonica/text-recognize\n",
        "! git clone https://github.com/devluz2023/visao-computacional.git\n"
      ],
      "metadata": {
        "id": "_71PrGs5Zd7q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c6a4ee-cf2a-4927-f795-e85815434095"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'text-recognize'...\n",
            "remote: Enumerating objects: 148, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 148 (delta 3), reused 1 (delta 1), pack-reused 144\u001b[K\n",
            "Receiving objects: 100% (148/148), 37.21 MiB | 30.90 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n",
            "Cloning into 'visao-computacional'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 31 (delta 14), reused 5 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (31/31), 37.82 MiB | 34.98 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "import numpy as np\n",
        "import cv2\n",
        "import re\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph\n",
        "from reportlab.lib.styles import getSampleStyleSheet\n",
        "from PIL import ImageFont, ImageDraw, Image\n",
        "from pytesseract import Output\n",
        "from google.colab.patches import cv2_imshow\n",
        "import fitz\n"
      ],
      "metadata": {
        "id": "P2-LQ1mSZi0W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pytesseract.__version__"
      ],
      "metadata": {
        "id": "4lyWhm_BcjEW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8ee1b012-d7f0-459f-b2ae-25b3ff30e532"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.3.10'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.__version__"
      ],
      "metadata": {
        "id": "RoWz5BG5ck6O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8a73db2d-f0be-442c-c7da-5ab9e8b56baa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir tessdata\n",
        "!wget -O ./tessdata/por.traineddata https://github.com/tesseract-ocr/tessdata/blob/main/por.traineddata?raw=true\n",
        "!wget -O ./tessdata/eng.traineddata https://github.com/tesseract-ocr/tessdata/blob/main/eng.traineddata?raw=true"
      ],
      "metadata": {
        "id": "LqgDSSufKbSr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5638085-acdc-4e5a-9144-0172f15b8652"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-12 00:27:59--  https://github.com/tesseract-ocr/tessdata/blob/main/por.traineddata?raw=true\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/tesseract-ocr/tessdata/raw/main/por.traineddata [following]\n",
            "--2024-03-12 00:27:59--  https://github.com/tesseract-ocr/tessdata/raw/main/por.traineddata\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/tesseract-ocr/tessdata/main/por.traineddata [following]\n",
            "--2024-03-12 00:27:59--  https://raw.githubusercontent.com/tesseract-ocr/tessdata/main/por.traineddata\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15336931 (15M) [application/octet-stream]\n",
            "Saving to: ‘./tessdata/por.traineddata’\n",
            "\n",
            "./tessdata/por.trai 100%[===================>]  14.63M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-03-12 00:27:59 (114 MB/s) - ‘./tessdata/por.traineddata’ saved [15336931/15336931]\n",
            "\n",
            "--2024-03-12 00:27:59--  https://github.com/tesseract-ocr/tessdata/blob/main/eng.traineddata?raw=true\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/tesseract-ocr/tessdata/raw/main/eng.traineddata [following]\n",
            "--2024-03-12 00:27:59--  https://github.com/tesseract-ocr/tessdata/raw/main/eng.traineddata\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/tesseract-ocr/tessdata/main/eng.traineddata [following]\n",
            "--2024-03-12 00:27:59--  https://raw.githubusercontent.com/tesseract-ocr/tessdata/main/eng.traineddata\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23466654 (22M) [application/octet-stream]\n",
            "Saving to: ‘./tessdata/eng.traineddata’\n",
            "\n",
            "./tessdata/eng.trai 100%[===================>]  22.38M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-03-12 00:28:00 (159 MB/s) - ‘./tessdata/eng.traineddata’ saved [23466654/23466654]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entendendo os dados"
      ],
      "metadata": {
        "id": "LvZ-NYWu1-wo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mostrar(img):\n",
        "  fig = plt.gcf() # busca a figura atual\n",
        "  fig.set_size_inches(20, 10) #define o tamanho\n",
        "  plt.axis(\"off\") #remove a visualização dos eixos\n",
        "  plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) #faz a conversão de cores com o OpenCV\n",
        "  plt.show() # mostra a imagem\n",
        "\n",
        "\n",
        "\n",
        "def translate_to_portuguese(text):\n",
        "    translator = Translator(to_lang=\"pt\")\n",
        "    translated_text = translator.translate(text)\n",
        "    return translated_text\n",
        "\n",
        "def text_to_pdf(text, output_pdf):\n",
        "    doc = SimpleDocTemplate(output_pdf, pagesize=letter)\n",
        "    styles = getSampleStyleSheet()\n",
        "    content = [Paragraph(text, styles[\"Normal\"])]\n",
        "    doc.build(content)\n",
        "\n",
        "def pdf_to_images(pdf_path, output_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Open the PDF file\n",
        "    with fitz.open(pdf_path) as pdf_document:\n",
        "        num_pages = pdf_document.page_count\n",
        "\n",
        "        # Iterate through each page\n",
        "        for page_num in range(num_pages):\n",
        "            # Render the page as an image\n",
        "            image = page_to_image(pdf_document, page_num)\n",
        "\n",
        "            # Save the image\n",
        "            image_path = os.path.join(output_folder, f\"page_{page_num + 1}.png\")\n",
        "            image.save(image_path)\n",
        "\n",
        "            print(f\"Page {page_num + 1} converted to {image_path}\")\n",
        "\n",
        "def page_to_image(pdf_document, page_num):\n",
        "    # Render the PDF page as an image\n",
        "    page = pdf_document.load_page(page_num)\n",
        "    pix = page.get_pixmap()\n",
        "    return Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)"
      ],
      "metadata": {
        "id": "W7NIMW_YMgpT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pdf_path = \"/content/visao-computacional/Genetics_and_the_races_of_man;_an_introduction_to_modern_physical_115659.pdf\"\n",
        "\n",
        "# Output folder for the images\n",
        "output_folder = \"output_images\"\n",
        "\n",
        "projeto = \"/content/output_images\"\n",
        "caminho = [os.path.join(projeto, f) for f in os.listdir(projeto)]\n",
        "print(caminho)\n",
        "\n",
        "# Convert PDF to images\n",
        "pdf_to_images(pdf_path, output_folder)\n",
        "\n",
        "for imagem in caminho:\n",
        "  imagem = cv2.imread(imagem)\n",
        "  mostrar(imagem)"
      ],
      "metadata": {
        "id": "-YkohncwNN9C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "19e983c3-0c84-41ff-9789-e92a8ffd5c8a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/output_images'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-4b7f3bf78d80>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprojeto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/output_images\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcaminho\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojeto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojeto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaminho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/output_images'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config_tesseract = \"--tessdata-dir tessdata\"\n",
        "\n",
        "def OCR_processa(img, config_tesseract):\n",
        "  texto = pytesseract.image_to_string(img, lang='por', config=config_tesseract)\n",
        "  return texto"
      ],
      "metadata": {
        "id": "7bS9usEvNgtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Reconhecimento do texto"
      ],
      "metadata": {
        "id": "HyeCwA-MmbNI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto_completo = ''\n",
        "nome_txt = 'resultados_ocr.txt'"
      ],
      "metadata": {
        "id": "s56A6H5N1nuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for imagem in caminho: # percorre as imagens no caminho\n",
        "  img = cv2.imread(imagem)\n",
        "  nome_imagem = os.path.split(imagem)[-1] ## recebe os nomes e diretórios das imagens, quebrados, precisamos apenas do -1 (última posição do diretório)\n",
        "  nome_divisao = '===================\\n' + str(nome_imagem) #divisão + nome da imagem que está sendo vista\n",
        "  texto_completo = texto_completo + nome_divisao + '\\n' # recebe o texto completo + a divisão + /n para pular a linha\n",
        "  texto = OCR_processa(img, config_tesseract) #passa a imagem que vamos utilizar, no caso em cada imagem\n",
        "  texto_completo = texto_completo + texto # concatena as duas variáveis"
      ],
      "metadata": {
        "id": "9NRfDmb0P8Z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texto_completo"
      ],
      "metadata": {
        "id": "fl-PEH4oQ0oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate_to_portuguese(texto_completo)"
      ],
      "metadata": {
        "id": "YRZl8ueC8hrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Salvando o arquivo em txt\n",
        "arquivo_txt = open(nome_txt, 'w+') # a+ é para colocar no final do arquivo, w+ para sobre escrever o arquivo\n",
        "arquivo_txt.write(texto_completo + '\\n') #passa o texto que quer adicionar\n",
        "arquivo_txt.close()"
      ],
      "metadata": {
        "id": "6fhk8w-6Q-75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Busca de ocorrências"
      ],
      "metadata": {
        "id": "W85M7dx8sXjx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Nos textos"
      ],
      "metadata": {
        "id": "zm-1t2s7tH23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "termo_pesquisa = 'learning'"
      ],
      "metadata": {
        "id": "5vqOPjkB1q7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(nome_txt) as f: # abre o documento txt\n",
        "  ocorrencias = [i.start() for i in re.finditer(termo_pesquisa, f.read())] #ocorrencia é uma lista.\n",
        "  #inicia-se em i e o termo re é de expressões regulares, o módulo finditer é para encontrar um termo de pesquisa dentro do arquivo\n",
        "  #por isso os parâmetros são, respectivamente, termo_pesquisa e arquivo a ser lido."
      ],
      "metadata": {
        "id": "nThTta70S75B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ocorrencias"
      ],
      "metadata": {
        "id": "MAAMJlhnTeGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Na listagem de imagens"
      ],
      "metadata": {
        "id": "ephsI8_5tJoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for imagem in caminho:\n",
        "  img = cv2.imread(imagem) #carrega a imagem\n",
        "  nome_imagem = os.path.split(imagem)[-1] # passa a imagem e acessa a última posição do diretório\n",
        "  print('====================\\n' + str(nome_imagem)) # separação + nome da imagem\n",
        "\n",
        "  texto = OCR_processa(img, config_tesseract) #usando o OCR\n",
        "\n",
        "  ocorrencias = [i.start() for i in re.finditer(termo_pesquisa, texto)] #usando o finditer novamente no texto\n",
        "\n",
        "  print('Número de ocorrências para o termo: {}: {}'.format(termo_pesquisa, len(ocorrencias)))\n",
        "  #primeira chaves é para termo de pesquisa e a segunda é para ocorrencias\n",
        "  print('\\n')"
      ],
      "metadata": {
        "id": "_yqh2CkF1r9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Reconhecimento na imagem"
      ],
      "metadata": {
        "id": "t2y8slXLxhKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fonte_dir = '/content/text-recognize/Imagens/calibri.ttf'"
      ],
      "metadata": {
        "id": "ib8Sjodz1vGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def escreve_texto(texto, x, y, img, fonte_dir, cor=(50, 50, 255), tamanho=16):\n",
        "  fonte = ImageFont.truetype(fonte_dir, tamanho)\n",
        "  img_pil = Image.fromarray(img)\n",
        "  draw = ImageDraw.Draw(img_pil)\n",
        "  draw.text((x, y-tamanho), texto, font = fonte, fill = cor)\n",
        "  img = np.array(img_pil)\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "IcIQQa3yVbvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_conf = 30  #@param {type:\"slider\", min:0, max:100}"
      ],
      "metadata": {
        "id": "1EsiRreKVgho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def caixa_texto(i, resultado, img, cor=(255, 100, 0)):\n",
        "  x = resultado[\"left\"][i]\n",
        "  y = resultado[\"top\"][i]\n",
        "  w = resultado[\"width\"][i]\n",
        "  h = resultado[\"height\"][i]\n",
        "\n",
        "  cv2.rectangle(img, (x, y), (x + w, y + h), cor, 2)\n",
        "\n",
        "  return x, y, img"
      ],
      "metadata": {
        "id": "3OJjc_dEVoAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def OCR_processa_imagem(img, termo_pesquisa, config_tesseract, min_conf):\n",
        "  resultado = pytesseract.image_to_data(img, config=config_tesseract, lang='por', output_type=Output.DICT) #imagem para dados, que já fizemos anteriormente\n",
        "  num_ocorrencias = 0 #inicializando como 0\n",
        "\n",
        "  for i in range(0, len(resultado['text'])): # vai de 0 ao tamanho do número de valores do texto\n",
        "    confianca = int(resultado['conf'][i]) # qual a confiança da detecção\n",
        "    if confianca > min_conf: # se a confiança for maior que o valor mínimo, passa para a linha abaixo\n",
        "      texto = resultado['text'][i] #texto será igual ao resultado text no momento i\n",
        "      if termo_pesquisa in texto: #se o termo de pesquisa estiver no texto:\n",
        "        x, y, img = caixa_texto(i, resultado, img, (0,0,255)) # faz a caixa de bounding box\n",
        "        img = escreve_texto(texto, x, y, img, fonte_dir, (50,50,225), 14) #escreve o texto\n",
        "\n",
        "        num_ocorrencias += 1 #faz a iteração no num de ocorrências e volta para o laço até acabar o texto\n",
        "  return img, num_ocorrencias"
      ],
      "metadata": {
        "id": "Bst6g0ZGVuYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "termo_pesquisa = 'learning'\n",
        "\n",
        "for imagem in caminho:\n",
        "  img = cv2.imread(imagem) #carrega a imagem\n",
        "  img_original = img.copy() #cria uma cópia da imagem para não escrever em cima da original\n",
        "\n",
        "  nome_imagem = os.path.split(imagem)[-1] # passa a imagem e acessa a última posição do diretório\n",
        "  print('===================\\n' + str(nome_imagem))  # separação + nome da imagem\n",
        "\n",
        "  img, numero_ocorrencias = OCR_processa_imagem(img, termo_pesquisa, config_tesseract, min_conf) #usando o OCR_processa_imagem\n",
        "  print('Número de ocorrências para {} em {}: {}'.format(termo_pesquisa, nome_imagem, numero_ocorrencias))\n",
        "    #primeira chaves é para termo de pesquisa e a segunda nome das imagens e a terceira é o numeros de ocorrencias\n",
        "  print('\\n')\n",
        "\n",
        "  mostrar(img)"
      ],
      "metadata": {
        "id": "xfz4N8mnWrDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desafio - Reconhecendo letras maíusculas e minúsculas"
      ],
      "metadata": {
        "id": "hMTRoN-ubOoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def OCR_processa_imagem(img, termo_pesquisa, config_tesseract, min_conf):\n",
        "  resultado = pytesseract.image_to_data(img, config=config_tesseract, lang='por', output_type=Output.DICT) #imagem para dados, que já fizemos anteriormente\n",
        "  num_ocorrencias = 0 #inicializando como 0\n",
        "\n",
        "  for i in range(0, len(resultado['text'])): # vai de 0 ao tamanho do número de valores do texto\n",
        "    confianca = int(resultado['conf'][i]) # qual a confiança da detecção\n",
        "    if confianca > min_conf: # se a confiança for maior que o valor mínimo, passa para a linha abaixo\n",
        "      texto = resultado['text'][i] #texto será igual ao resultado text no momento i\n",
        "      if termo_pesquisa.lower() in texto.lower(): #se o termo de pesquisa estiver no texto:\n",
        "        x, y, img = caixa_texto(i, resultado, img, (0,0,255)) # faz a caixa de bounding box\n",
        "        img = escreve_texto(texto, x, y, img, fonte_dir, (50,50,225), 14) #escreve o texto\n",
        "\n",
        "        num_ocorrencias += 1 #faz a iteração no num de ocorrências e volta para o laço até acabar o texto\n",
        "  return img, num_ocorrencias"
      ],
      "metadata": {
        "id": "GoMOzRnKjGUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "termo_pesquisa = 'learning'\n",
        "\n",
        "for imagem in caminho:\n",
        "  img = cv2.imread(imagem) #carrega a imagem\n",
        "  img_original = img.copy() #cria uma cópia da imagem para não escrever em cima da original\n",
        "\n",
        "  nome_imagem = os.path.split(imagem)[-1] # passa a imagem e acessa a última posição do diretório\n",
        "  print('===================\\n' + str(nome_imagem))  # separação + nome da imagem\n",
        "\n",
        "  img, numero_ocorrencias = OCR_processa_imagem(img, termo_pesquisa, config_tesseract, min_conf) #usando o OCR_processa_imagem\n",
        "  print('Número de ocorrências para {} em {}: {}'.format(termo_pesquisa, nome_imagem, numero_ocorrencias))\n",
        "    #primeira chaves é para termo de pesquisa e a segunda nome das imagens e a terceira é o numeros de ocorrencias\n",
        "  print('\\n')\n",
        "\n",
        "  mostrar(img)"
      ],
      "metadata": {
        "id": "TT-yUgOcjGrO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}